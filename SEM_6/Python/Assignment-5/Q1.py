'''
ğŸ”¹ Single Layer Perceptron (SLP)
--------------------------------

âœ… Definition:
A Single Layer Perceptron is the most basic form of a neural network. It consists of:
- An input layer
- An output layer with no hidden layers

âœ… Architecture:
Input Layer       Output
 (x1)   â”€â”
 (x2)   â”€â”¼â”€â”€â–º (weighted sum + activation) â–º Å·
 (x3)   â”€â”˜

Each input is multiplied by a weight, summed with a bias, and passed through an activation function (usually step or sigmoid for binary classification).

âœ… Loss Function:
For binary classification:
    ğ“›_binary = -[y * log(Å·) + (1 - y) * log(1 - Å·)]

Where:
- y is the true label (0 or 1)
- Å· is the predicted probability

--------------------------------------------------

ğŸ”¹ Multilayer Perceptron (MLP)
------------------------------

âœ… Definition:
A Multilayer Perceptron is a feedforward neural network with one or more hidden layers between input and output. It can model non-linear relationships.

âœ… Architecture:
Input Layer     Hidden Layer(s)        Output Layer
 (x1)   â”€â”         (h1)   â”€â”
 (x2)   â”€â”¼â”€â–º W1 â”€â–º (h2)   â”€â”¼â”€â–º W2 â”€â–º (Å·)
 (x3)   â”€â”˜         (h3)   â”€â”˜

- Activation functions in hidden layers: ReLU, tanh, etc.
- Output layer activation: softmax (multi-class) or sigmoid (binary)

âœ… Loss Function:
For multi-class classification using softmax:
    ğ“›_categorical = -âˆ‘[i=1 to C] y_i * log(Å·_i)

Where:
- C = number of classes
- y_i = 1 if true class is i, else 0
- Å·_i = predicted probability for class i

--------------------------------------------------

ğŸ§  Summary Table:

| Aspect         | SLP                        | MLP                            |
|----------------|----------------------------|--------------------------------|
| Layers         | 1 (no hidden layers)       | â‰¥2 (at least one hidden layer) |
| Function       | Linear classifier          | Non-linear modeling            |
| Suitable for   | Linearly separable data    | Complex problems (e.g., images)|
| Activation     | Step / Sigmoid             | ReLU / Tanh / Sigmoid / Softmax |
'''